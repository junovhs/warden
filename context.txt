================================================================================
FILE: .gitignore
================================================================================
# Rust build artifacts
/target/
/docs/
/Cargo.lock

# Logs and temp files
*.log
*.tmp
*.bak

# Generated AI pack and test fixtures
ai-pack/
tests/tmp/
tmp/
*.manifest.json

# Editor/OS files
.DS_Store
Thumbs.db
.idea/
.vscode/
*.swp
*.swo

# Git / OS cruft
*~
*.orig

# Node / frontend extras
node_modules/
dist/
build/
coverage/
.env

# Python extras
__pycache__/
.venv/
venv/

# Repomix or AI output
*.xml
*.jsonl

# Ignore everything inside /target/release except binaries we care about
!/target/release/saccade.exe
!/target/release/gauntlet.exe

================================================================================
FILE: Cargo.toml
================================================================================
[package]
name = "warden"
version = "0.2.0"
edition = "2021"

[lib]
name = "warden_core"
path = "src/lib.rs"

[[bin]]
name = "warden"
path = "src/bin/warden.rs"

[[bin]]
name = "knit"
path = "src/bin/knit.rs"

[dependencies]
anyhow = "1.0"
thiserror = "1.0"
regex = "1.10"
walkdir = "2.5"
clap = { version = "4.5", features = ["derive"] }
ignore = "0.4"
colored = "2.1"
rayon = "1.10"
once_cell = "1.19"

# THE BRAINS
tiktoken-rs = "0.5"

# Structural Parsing
tree-sitter = "0.20"
tree-sitter-rust = "0.20"
tree-sitter-python = "0.20"
tree-sitter-typescript = "0.20"
tree-sitter-javascript = "0.20"


================================================================================
FILE: LICENSE
================================================================================
MIT License

Copyright (c) 2025 Spencer Nunamaker

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.


================================================================================
FILE: README.md
================================================================================
# üõ°Ô∏è Warden Protocol

**Architecture Governance for the AI Era.**

> *"We do not ask the AI to write good code. We enforce good code via mechanical constraints."*

Warden is a local toolchain designed to enforce **Code With Intent (POT)**. It solves the "Context Drift" and "Hallucination" problems common in AI coding by enforcing strict structural discipline (Atomicity, Naming, Safety) before code is committed.

## The Ecosystem

This repository contains two binaries that share a single logic core:

1.  **`warden` (The Enforcer):** A structural linter that rejects bloat, complexity, and unsafe code.
2.  **`knit` (The Messenger):** A smart context-packer that serializes your repository for AI consumption, respecting Warden's filters automatically.

---

## 1. The Warden (Linter)

Warden does not check if your code works. It checks if your code is **maintainable**. It enforces the "3 Laws" of this architecture:

### The 3 Laws
1.  **The Law of Atomicity (Anti-Bloat)**
    *   **Rule:** No file may exceed **200 lines of code**.
    *   **Goal:** Forces modularity. Small files fit in AI context windows perfectly and reduce regression errors.
2.  **The Law of Bluntness (Naming)**
    *   **Rule:** Function names must be **‚â§ 3 words** (e.g., `fetchUser` ‚úÖ, `fetchUserAndSaveToDb` ‚ùå).
    *   **Goal:** Enforces Single Responsibility Principle (SRP). If you can't name it simply, split it.
3.  **The Law of Paranoia (Safety)**
    *   **Rule:** Logic files must contain explicit error handling (`Result`, `try/catch`, `Option`).
    *   **Goal:** Prevents "Silent Failures."

### Usage
```bash
# Run inside any Git repo
warden

# Force scan ignored files
warden --no-git

# Verbose mode (see exactly what it checks)
warden -v
```

**Bypass:** To intentionally skip a file (e.g., a UI component with no logic), add this comment to the top of the file:
```rust
// warden:ignore
```

---

## 2. Knit (Context Packer)

Knit is the bridge between your filesystem and the LLM. It stitches your "Atomic" files into a single text stream with clear headers.

### Features
*   **Smart Defaults:** Automatically strips noise (`node_modules`, `target`, `_assets`, `lockfiles`, `tests`, `docs`). You get the **Kernel** of the code, not the fluff.
*   **Shared Brain:** Uses the exact same ignore logic as Warden.
*   **Security:** Filters out secrets (`.env`, keys) and binaries (`.png`, `.exe`) automatically.

### Usage
```bash
# Generates a clean 'context.txt' in the current folder
knit

# Pipe directly to clipboard (Mac)
knit --stdout | pbcopy

# Pipe directly to clipboard (Linux)
knit --stdout | xclip -selection c
```

---

## ‚öôÔ∏è Configuration

Warden and Knit work out-of-the-box with "Smart Defaults" (ignoring `dist`, `build`, `assets`, etc).

To add custom excludes for a specific project, create a `.wardenignore` file in the project root:

```text
# .wardenignore
legacy_code/
experiment.rs
scripts/
```

---

## üöÄ Installation

Requires Rust (`cargo`).

```bash
# Clone and install globally
git clone https://github.com/yourusername/warden.git
cd warden
cargo install --path .
```

**Recommended Shell Aliases:**
Add these to your `.zshrc` or `.bashrc` for the full workflow:

```bash
# Mac
alias gcp="knit --stdout | pbcopy && echo 'üìã Context copied.'"

# Linux
# alias gcp="knit --stdout | xclip -selection c && echo 'üìã Context copied.'"
```

---

## ü§ñ The AI System Prompt

To make the AI obey Warden, paste this into your System Prompt / Custom Instructions:

```text
ROLE: High-Integrity Systems Architect.
CONTEXT: You are coding inside a strict "Code With Intent" environment enforced by a binary linter called Warden.

THE 3 LAWS (Non-Negotiable):
1. LAW OF ATOMICITY (No Monoliths):
   - Files MUST be < 200 Lines of Code.
   - If a file grows too large, split it immediately.
   - React/UI: Split VIEW (Component.tsx) from LOGIC (useComponent.ts).

2. LAW OF PARANOIA (Safety First):
   - Functions MUST use explicit error handling (Result, try/catch, Option). No silent failures.
   - If a component is pure UI (visuals only), add "// warden:ignore" at the top.

3. LAW OF BLUNTNESS (Naming):
   - Function names Max 3 words (e.g., `fetchData` is good; `fetchDataAndProcess` is bad).

OPERATIONAL PROTOCOL:
1. Scan: Read the provided context.
2. Generate: Output WHOLE FILES with the filename in a header. Do not use diffs.
3. Verify: Ask yourself: "Will Warden reject this?" before printing.
```

---

**License:** MIT  
**Philosophy:** Code With Intent (POT)


================================================================================
FILE: src/bin/knit.rs
================================================================================
use anyhow::Result;
use clap::Parser;
use colored::Colorize;
use std::fmt::Write;
use std::fs;

use warden_core::config::{Config, GitMode};
use warden_core::enumerate::FileEnumerator;
use warden_core::filter::FileFilter;
use warden_core::heuristics::HeuristicFilter;
use warden_core::tokens::Tokenizer;

#[derive(Parser)]
#[command(name = "knit")]
#[command(about = "Stitches atomic files into a single context file.")]
#[allow(clippy::struct_excessive_bools)]
struct Cli {
    #[arg(long, short)]
    stdout: bool,
    #[arg(long, short)]
    verbose: bool,
    #[arg(long)]
    git_only: bool,
    #[arg(long)]
    no_git: bool,
    #[arg(long)]
    code_only: bool,
}

fn main() -> Result<()> {
    let cli = Cli::parse();

    let mut config = Config::new();
    config.verbose = cli.verbose;
    config.code_only = cli.code_only;

    if cli.git_only {
        config.git_mode = GitMode::Yes;
    } else if cli.no_git {
        config.git_mode = GitMode::No;
    }

    config.load_ignore_file();
    config.validate()?;

    if !cli.stdout {
        println!("üß∂ Knitting repository...");
    }

    let enumerator = FileEnumerator::new(config.clone());
    let raw_files = enumerator.enumerate()?;

    let heuristic_filter = HeuristicFilter::new();
    let heuristics_files = heuristic_filter.filter(raw_files);

    let filter = FileFilter::new(config.clone())?;
    let target_files = filter.filter(heuristics_files);

    if cli.verbose {
        eprintln!("üì¶ Packing {} files...", target_files.len());
    }

    let mut full_context = String::with_capacity(100_000);

    for path in &target_files {
        let path_str = path.to_string_lossy();

        writeln!(
            full_context,
            "================================================================================"
        )
        .unwrap();

        writeln!(full_context, "FILE: {path_str}").unwrap();

        writeln!(
            full_context,
            "================================================================================"
        )
        .unwrap();

        match fs::read_to_string(path) {
            Ok(content) => {
                full_context.push_str(&content);
            }
            Err(e) => {
                writeln!(full_context, "<ERROR READING FILE: {e}>").unwrap();
            }
        }
        full_context.push_str("\n\n");
    }

    // Count tokens
    let token_count = Tokenizer::count(&full_context);

    if cli.stdout {
        print!("{full_context}");
        eprintln!(
            "\nüìä Context Size: {} tokens",
            token_count.to_string().yellow().bold()
        );
    } else {
        fs::write("context.txt", &full_context)?;
        println!("‚úÖ Generated 'context.txt'");
        println!(
            "üìä Context Size: {} tokens",
            token_count.to_string().yellow().bold()
        );
    }

    Ok(())
}


================================================================================
FILE: src/bin/warden.rs
================================================================================
use anyhow::Result;
use clap::Parser;
use colored::Colorize;
use std::process;

// Use the shared library modules
use warden_core::config::{Config, GitMode};
use warden_core::detection::Detector;
use warden_core::enumerate::FileEnumerator;
use warden_core::filter::FileFilter;
use warden_core::heuristics::HeuristicFilter;
use warden_core::rules::RuleEngine;

#[derive(Parser)]
#[command(name = "warden")]
#[command(about = "Structural linter for Code With Intent")]
#[allow(clippy::struct_excessive_bools)]
struct Cli {
    #[arg(long, short)]
    verbose: bool,
    #[arg(long)]
    git_only: bool,
    #[arg(long)]
    no_git: bool,
    #[arg(long)]
    code_only: bool,
}

fn main() -> Result<()> {
    let cli = Cli::parse();

    // Strict initialization using struct update syntax
    let mut config = Config {
        verbose: cli.verbose,
        code_only: cli.code_only,
        ..Config::default()
    };

    if cli.git_only {
        config.git_mode = GitMode::Yes;
    } else if cli.no_git {
        config.git_mode = GitMode::No;
    }

    // Load the ignore file before validation/enumeration
    config.load_ignore_file();
    config.validate()?;

    let enumerator = FileEnumerator::new(config.clone());
    let raw_files = enumerator.enumerate()?;

    // Context: Detection
    // Unit structs should be instantiated directly, not via ::default()
    let detector = Detector;
    if let Ok(systems) = detector.detect_build_systems(&raw_files) {
        if !systems.is_empty() && config.verbose {
            let sys_list: Vec<String> = systems.iter().map(ToString::to_string).collect();
            println!("üîé Detected Ecosystem: [{}]", sys_list.join(", ").cyan());
        }
    }

    // Unit struct instantiation
    let heuristic_filter = HeuristicFilter;
    let heuristics_files = heuristic_filter.filter(raw_files);

    let filter = FileFilter::new(config)?;
    let target_files = filter.filter(heuristics_files);

    if target_files.is_empty() {
        println!("No files to scan.");
        return Ok(());
    }

    println!(
        "üëÆ Warden scanning {} files (AST + Token Analysis)...",
        target_files.len()
    );

    let engine = RuleEngine::default();
    let mut total_failures = 0;

    for path in target_files {
        if let Ok(passed) = engine.check_file(&path) {
            if !passed {
                total_failures += 1;
            }
        }
    }

    if total_failures > 0 {
        println!(
            "{}",
            format!("‚ùå Warden found {total_failures} violations.")
                .red()
                .bold()
        );
        process::exit(1);
    } else {
        println!(
            "{}",
            "‚úÖ All Clear. Code structure is clean.".green().bold()
        );
        process::exit(0);
    }
}


================================================================================
FILE: src/config.rs
================================================================================
use crate::error::Result;
use regex::Regex;
use std::fs;
use std::path::Path;

#[derive(Debug, Clone)]
pub enum GitMode {
    Auto,
    Yes,
    No,
}

#[derive(Debug, Clone)]
pub struct Config {
    pub git_mode: GitMode,
    pub include_patterns: Vec<Regex>,
    pub exclude_patterns: Vec<Regex>,
    pub code_only: bool,
    pub verbose: bool,
}

impl Config {
    #[must_use]
    pub fn new() -> Self {
        Self {
            git_mode: GitMode::Auto,
            include_patterns: Vec::new(),
            exclude_patterns: Vec::new(),
            code_only: false,
            verbose: false,
        }
    }

    /// Validates the configuration.
    ///
    /// # Errors
    ///
    /// Currently always returns `Ok`. Reserved for future validation logic
    /// that might return an error if configurations are invalid.
    pub fn validate(&self) -> Result<()> {
        Ok(())
    }

    pub fn load_ignore_file(&mut self) {
        let ignore_path = Path::new(".wardenignore");
        if ignore_path.exists() {
            if let Ok(content) = fs::read_to_string(ignore_path) {
                for line in content.lines() {
                    let trimmed = line.trim();
                    if trimmed.is_empty() || trimmed.starts_with('#') {
                        continue;
                    }
                    if let Ok(re) = Regex::new(trimmed) {
                        self.exclude_patterns.push(re);
                    }
                }
            }
        }
    }
}

impl Default for Config {
    fn default() -> Self {
        Self::new()
    }
}

// THE "SMART PRUNE" LIST
pub const PRUNE_DIRS: &[&str] = &[
    // 1. Artifacts & Build Garbage
    ".git",
    "node_modules",
    "target",
    "dist",
    "build",
    "out",
    "gen",
    "generated",
    ".venv",
    "venv",
    ".tox",
    ".cache",
    "__pycache__",
    "coverage",
    "vendor",
    "third_party",
    // 2. Lockfiles (Noise)
    "package-lock.json",
    "yarn.lock",
    "pnpm-lock.yaml",
    "Cargo.lock",
    "Gemfile.lock",
    "composer.lock",
    "poetry.lock",
    // 3. Assets (Binary/Visual Noise)
    "_assets",
    "assets",
    "static",
    "public",
    "media",
    "images",
    "img",
    "fonts",
    "icons",
    "res",
    "resources",
    // 4. Context/Meta (Tests & Docs)
    "tests",
    "test",
    "spec",
    "__tests__",
    "docs",
    "doc",
    "documentation",
    "examples",
    "samples",
];

// Extensions that represent binary data or useless machine-generated text (like .map)
pub const BIN_EXT_PATTERN: &str = r"(?i)\.(png|jpe?g|gif|svg|ico|icns|webp|woff2?|ttf|otf|pdf|mp4|mov|mkv|avi|mp3|wav|flac|zip|gz|bz2|xz|7z|rar|jar|csv|tsv|parquet|sqlite|db|bin|exe|dll|so|dylib|pdb|pkl|onnx|torch|tgz|zst|lock|log|map|min\.js|min\.css)$";

// Credentials detection
pub const SECRET_PATTERN: &str = r"(?i)(^\.?env(\..*)?$|/\.?env(\..*)?$|(^|/)(id_rsa(\.pub)?|id_ed25519(\.pub)?|.*\.(pem|p12|jks|keystore|pfx))$)";

// Code extension regex (for --code-only mode)
pub const CODE_EXT_PATTERN: &str = r"(?i)\.(c|h|cc|hh|cpp|hpp|rs|go|py|js|jsx|ts|tsx|java|kt|kts|rb|php|scala|cs|swift|m|mm|lua|sh|bash|zsh|fish|ps1|sql|html|xhtml|xml|xsd|xslt|yaml|yml|toml|ini|cfg|conf|json|ndjson|md|rst|tex|s|asm|cmake|gradle|proto|graphql|gql|nix|dart|scss|less|css)$";

pub const CODE_BARE_PATTERN: &str =
    r"(?i)(Makefile|Dockerfile|dockerfile|CMakeLists\.txt|BUILD|WORKSPACE)$";


================================================================================
FILE: src/detection.rs
================================================================================
use crate::error::Result;
use std::collections::HashSet;
use std::fmt;
use std::path::Path;

#[derive(Debug, PartialEq, Eq, Hash, Clone, Copy)]
pub enum BuildSystemType {
    Rust,
    Node,
    Python,
    Go,
    CMake,
    Conan,
}

impl fmt::Display for BuildSystemType {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "{self:?}")
    }
}

pub struct Detector;

impl Detector {
    #[must_use]
    pub fn new() -> Self {
        Self
    }

    /// Detects build systems in the file list.
    ///
    /// # Errors
    ///
    /// Returns error if underlying detection logic fails.
    pub fn detect_build_systems(
        &self,
        files: &[std::path::PathBuf],
    ) -> Result<Vec<BuildSystemType>> {
        let mut detected = HashSet::new();

        for file in files {
            if Self::is_cargo(file) {
                detected.insert(BuildSystemType::Rust);
            }
            if Self::is_npm(file) {
                detected.insert(BuildSystemType::Node);
            }
            if Self::is_python(file) {
                detected.insert(BuildSystemType::Python);
            }
            if Self::is_go(file) {
                detected.insert(BuildSystemType::Go);
            }
            if Self::is_cmake(file) {
                detected.insert(BuildSystemType::CMake);
            }
            if Self::is_conan(file) {
                detected.insert(BuildSystemType::Conan);
            }
        }

        Ok(detected.into_iter().collect())
    }

    fn is_cargo(path: &Path) -> bool {
        path.ends_with("Cargo.toml")
    }
    fn is_npm(path: &Path) -> bool {
        path.ends_with("package.json")
    }
    fn is_python(path: &Path) -> bool {
        matches!(
            path.file_name().and_then(|n| n.to_str()),
            Some("requirements.txt" | "pyproject.toml" | "Pipfile")
        )
    }
    fn is_go(path: &Path) -> bool {
        path.ends_with("go.mod")
    }
    fn is_cmake(path: &Path) -> bool {
        let s = path.to_string_lossy();
        s.contains("CMakeLists.txt") || s.ends_with(".cmake")
    }
    fn is_conan(path: &Path) -> bool {
        matches!(
            path.file_name().and_then(|n| n.to_str()),
            Some("conanfile.txt" | "conanfile.py")
        )
    }
}

impl Default for Detector {
    fn default() -> Self {
        Self::new()
    }
}


================================================================================
FILE: src/enumerate.rs
================================================================================
use crate::config::{Config, PRUNE_DIRS};
use crate::error::{Result, WardenError};
use std::path::PathBuf;
use std::process::Command;
use walkdir::WalkDir;

pub struct FileEnumerator {
    config: Config,
}

impl FileEnumerator {
    #[must_use]
    pub fn new(config: Config) -> Self {
        Self { config }
    }

    /// Enumerates files based on configuration.
    ///
    /// # Errors
    ///
    /// Returns error if `git` fails in Git mode.
    pub fn enumerate(&self) -> Result<Vec<PathBuf>> {
        use crate::config::GitMode;

        match self.config.git_mode {
            GitMode::Yes => {
                if !Self::in_git_repo() {
                    return Err(WardenError::NotInGitRepo);
                }
                // Fixed: Self::filter_paths
                Ok(Self::filter_paths(Self::git_ls_files()?))
            }
            GitMode::No => Ok(self.walk_all_files()),
            GitMode::Auto => {
                if Self::in_git_repo() {
                    if let Ok(files) = Self::git_ls_files() {
                        // Fixed: Self::filter_paths
                        return Ok(Self::filter_paths(files));
                    }
                }
                Ok(self.walk_all_files())
            }
        }
    }

    // Fixed: Removed &self
    fn filter_paths(paths: Vec<PathBuf>) -> Vec<PathBuf> {
        paths
            .into_iter()
            .filter(|p| {
                for part in p.components() {
                    if let Some(s) = part.as_os_str().to_str() {
                        if PRUNE_DIRS.contains(&s) {
                            return false;
                        }
                    }
                }
                true
            })
            .collect()
    }

    fn in_git_repo() -> bool {
        let out = Command::new("git")
            .arg("rev-parse")
            .arg("--is-inside-work-tree")
            .output();

        matches!(out, Ok(o) if o.status.success())
    }

    fn git_ls_files() -> Result<Vec<PathBuf>> {
        let out = Command::new("git")
            .arg("ls-files")
            .arg("-z")
            .arg("--exclude-standard")
            .output()?;

        if !out.status.success() {
            return Err(WardenError::Other(format!(
                "git ls-files failed: exit {}",
                out.status
            )));
        }

        let mut paths = Vec::new();
        for chunk in out.stdout.split(|b| *b == 0) {
            if chunk.is_empty() {
                continue;
            }
            let s = String::from_utf8_lossy(chunk);
            paths.push(PathBuf::from(s.as_ref()));
        }
        Ok(paths)
    }

    fn walk_all_files(&self) -> Vec<PathBuf> {
        let mut paths = Vec::new();
        let mut errors = Vec::new();

        let walker = WalkDir::new(".").follow_links(false).into_iter();

        for item in walker.filter_entry(|e| {
            let name = e.file_name().to_string_lossy();
            // WalkDir filtering allows us to skip descending into "node_modules" entirely
            !PRUNE_DIRS.iter().any(|p| name == *p)
        }) {
            let entry = match item {
                Ok(e) => e,
                Err(e) => {
                    errors.push(format!("walkdir: {e}"));
                    continue;
                }
            };

            if entry.file_type().is_file() {
                let p = entry.path().strip_prefix(".").unwrap_or(entry.path());
                paths.push(p.to_path_buf());
            }
        }

        if !errors.is_empty() && self.config.verbose {
            eprintln!(
                "WARN: Encountered {} errors during file walk:",
                errors.len()
            );
            for (i, err) in errors.iter().take(5).enumerate() {
                eprintln!("  {}. {}", i + 1, err);
            }
        }

        paths
    }
}


================================================================================
FILE: src/error.rs
================================================================================
// src/error.rs
use std::path::PathBuf;
use thiserror::Error;

#[derive(Debug, Error)]
pub enum WardenError {
    #[error("I/O error: {source} (path: {path})")]
    Io {
        source: std::io::Error,
        path: PathBuf,
    },

    #[error("Not inside a Git repository")]
    NotInGitRepo,

    #[error("Regex error: {0}")]
    Regex(#[from] regex::Error),

    #[error("Generic error: {0}")]
    Other(String),
}

pub type Result<T> = std::result::Result<T, WardenError>;

// Allow `?` on std::io::Error by converting to WardenError::Io with unknown path.
impl From<std::io::Error> for WardenError {
    fn from(source: std::io::Error) -> Self {
        WardenError::Io {
            source,
            path: PathBuf::from("<unknown>"),
        }
    }
}

// Gracefully convert WalkDir errors
impl From<walkdir::Error> for WardenError {
    fn from(e: walkdir::Error) -> Self {
        WardenError::Other(e.to_string())
    }
}


================================================================================
FILE: src/filter.rs
================================================================================
use crate::config::{Config, BIN_EXT_PATTERN, CODE_BARE_PATTERN, CODE_EXT_PATTERN, SECRET_PATTERN};
use crate::error::Result;
use regex::Regex;
use std::path::Path;

pub struct FileFilter {
    config: Config,
    bin_ext_re: Regex,
    secret_re: Regex,
    code_ext_re: Option<Regex>,
    code_bare_re: Option<Regex>,
}

impl FileFilter {
    /// Creates a new file filter.
    ///
    /// # Errors
    ///
    /// Returns error if regex compilation fails.
    pub fn new(config: Config) -> Result<Self> {
        let bin_ext_re = Regex::new(BIN_EXT_PATTERN)?;
        let secret_re = Regex::new(SECRET_PATTERN)?;

        let (code_ext_re, code_bare_re) = if config.code_only {
            (
                Some(Regex::new(CODE_EXT_PATTERN)?),
                Some(Regex::new(CODE_BARE_PATTERN)?),
            )
        } else {
            (None, None)
        };

        Ok(Self {
            config,
            bin_ext_re,
            secret_re,
            code_ext_re,
            code_bare_re,
        })
    }

    #[must_use]
    pub fn filter(&self, files: Vec<std::path::PathBuf>) -> Vec<std::path::PathBuf> {
        files.into_iter().filter(|p| self.should_keep(p)).collect()
    }

    fn should_keep(&self, path: &Path) -> bool {
        let path_str = path.to_string_lossy().replace('\\', "/");

        if self.secret_re.is_match(&path_str) {
            return false;
        }

        if self.bin_ext_re.is_match(&path_str) {
            return false;
        }

        for pattern in &self.config.exclude_patterns {
            if pattern.is_match(&path_str) {
                return false;
            }
        }

        if !self.config.include_patterns.is_empty() {
            let mut matched = false;
            for pattern in &self.config.include_patterns {
                if pattern.is_match(&path_str) {
                    matched = true;
                    break;
                }
            }
            if !matched {
                return false;
            }
        }

        if let (Some(ext_re), Some(bare_re)) = (&self.code_ext_re, &self.code_bare_re) {
            if !(ext_re.is_match(&path_str) || bare_re.is_match(&path_str)) {
                return false;
            }
        }

        true
    }
}


================================================================================
FILE: src/heuristics.rs
================================================================================
use crate::config::{CODE_BARE_PATTERN, CODE_EXT_PATTERN};
use regex::Regex;
use std::collections::HashMap;
use std::fs;
use std::path::Path;
use std::sync::LazyLock;

// --- Configuration Constants for Heuristics ---
const MIN_TEXT_ENTROPY: f64 = 3.5;
const MAX_TEXT_ENTROPY: f64 = 5.5;

const BUILD_SYSTEM_PAMPS: &[&str] = &[
    "find_package",
    "add_executable",
    "target_link_libraries",
    "cmake_minimum_required",
    "project(",
    "add-apt-repository",
    "conanfile.py",
    "dependency",
    "require",
    "include",
    "import",
    "version",
    "dependencies",
];

// Pre-compiled regexes for known code files
static CODE_EXT_RE: LazyLock<Regex> = LazyLock::new(|| Regex::new(CODE_EXT_PATTERN).unwrap());
static CODE_BARE_RE: LazyLock<Regex> = LazyLock::new(|| Regex::new(CODE_BARE_PATTERN).unwrap());

pub struct HeuristicFilter;

impl HeuristicFilter {
    #[must_use]
    pub fn new() -> Self {
        Self
    }

    #[must_use]
    pub fn filter(&self, files: Vec<std::path::PathBuf>) -> Vec<std::path::PathBuf> {
        files
            .into_iter()
            .filter(|path| Self::should_keep(path))
            .collect()
    }

    fn should_keep(path: &Path) -> bool {
        let path_str = path.to_string_lossy();

        if CODE_EXT_RE.is_match(&path_str) || CODE_BARE_RE.is_match(&path_str) {
            return true;
        }

        if let Ok(entropy) = calculate_entropy(path) {
            if !(MIN_TEXT_ENTROPY..=MAX_TEXT_ENTROPY).contains(&entropy) {
                return false;
            }
        } else {
            return false;
        }

        if let Ok(content) = fs::read_to_string(path) {
            let lower_content = content.to_lowercase();
            for pamp in BUILD_SYSTEM_PAMPS {
                if lower_content.contains(pamp) {
                    return true;
                }
            }
        }

        true
    }
}

impl Default for HeuristicFilter {
    fn default() -> Self {
        Self::new()
    }
}

fn calculate_entropy(path: &Path) -> std::io::Result<f64> {
    let bytes = fs::read(path)?;
    if bytes.is_empty() {
        return Ok(0.0);
    }

    let mut freq_map = HashMap::new();
    for &byte in &bytes {
        *freq_map.entry(byte).or_insert(0) += 1;
    }

    // Suppress cast precision loss for 64-bit length; entropy approximation is fine.
    #[allow(clippy::cast_precision_loss)]
    let len = bytes.len() as f64;

    let entropy = freq_map.values().fold(0.0, |acc, &count| {
        let probability = f64::from(count) / len;
        acc - probability * probability.log2()
    });

    Ok(entropy)
}


================================================================================
FILE: src/lib.rs
================================================================================
pub mod config;
pub mod detection;
pub mod enumerate;
pub mod error;
pub mod filter;
pub mod heuristics;
pub mod rules;
pub mod tokens;


================================================================================
FILE: src/main.rs
================================================================================
use anyhow::Result;
use clap::Parser;
use colored::*;
use std::process;

// Module declarations
mod config;
mod detection;
mod enumerate;
mod error;
mod filter;
mod heuristics;
mod rules;

use crate::config::{Config, GitMode};
use crate::detection::Detector;
use crate::enumerate::FileEnumerator;
use crate::filter::FileFilter;
use crate::heuristics::HeuristicFilter;
use crate::rules::RuleEngine;

#[derive(Parser)]
#[command(name = "warden")]
#[command(about = "Structural linter for Code With Intent")]
struct Cli {
    /// Enable verbose logging
    #[arg(long, short)]
    verbose: bool,

    /// Force git-only mode (respect .gitignore)
    #[arg(long)]
    git_only: bool,

    /// Force no-git mode (scan everything)
    #[arg(long)]
    no_git: bool,

    /// Only scan code files (ignore configs/docs)
    #[arg(long)]
    code_only: bool,
}

fn main() -> Result<()> {
    let cli = Cli::parse();

    // 1. Setup & Validation
    let mut config = Config::new();
    config.verbose = cli.verbose;
    config.code_only = cli.code_only;

    // Wire up the GitMode enum variants (Resolves "Variant never constructed" warning)
    if cli.git_only {
        config.git_mode = GitMode::Yes;
    } else if cli.no_git {
        config.git_mode = GitMode::No;
    }

    // Call validate (Resolves "method never used" warning)
    config.validate()?;

    if config.verbose {
        println!("üîß Config loaded: GitMode::{:?}", config.git_mode);
    }

    // 2. Enumerate Files
    let enumerator = FileEnumerator::new(config.clone());
    let raw_files = enumerator.enumerate()?;

    // 3. Detection Layer (Resolves "Detector never constructed" warnings)
    // We use the detector to give context to the user about what we think this project is.
    let detector = Detector::new();
    let systems = detector.detect_build_systems(&raw_files)?;
    if !systems.is_empty() {
        let sys_list: Vec<String> = systems.iter().map(|s| s.to_string()).collect();
        println!("üîé Detected Ecosystem: [{}]", sys_list.join(", ").cyan());
    }

    // 4. Heuristics Layer (Resolves "HeuristicFilter never used" warnings)
    // Filters out high-entropy files (likely binaries/obfuscated code)
    let heuristic_filter = HeuristicFilter::new();
    let heuristics_files = heuristic_filter.filter(raw_files);

    // 5. Standard Filter Layer (Extension & Secrets)
    let filter = FileFilter::new(config)?;
    let target_files = filter.filter(heuristics_files);

    if target_files.is_empty() {
        println!("No files to scan.");
        return Ok(());
    }

    println!("üëÆ Warden scanning {} files...", target_files.len());

    // 6. Logic Engine (The Rules)
    let engine = RuleEngine::new();
    let mut total_failures = 0;

    for path in target_files {
        // We ignore the result error here (read failures) and just count logic failures
        if let Ok(passed) = engine.check_file(&path) {
            if !passed {
                total_failures += 1;
            }
        }
    }

    println!("---------------------------------------------------");
    if total_failures > 0 {
        println!(
            "{}",
            format!("‚ùå Warden found {} violations.", total_failures)
                .red()
                .bold()
        );
        process::exit(1);
    } else {
        println!(
            "{}",
            "‚úÖ All Clear. Code structure is clean.".green().bold()
        );
        process::exit(0);
    }
}


================================================================================
FILE: src/rules.rs
================================================================================
use crate::error::Result;
use crate::tokens::Tokenizer;
use colored::Colorize;
use std::fs;
use std::path::Path;
use tree_sitter::{Language, Node, Parser, Query, QueryCursor};

// --- CONFIGURATION ---
const TOKEN_LIMIT: usize = 2000;
const WORD_LIMIT: usize = 3;

pub struct RuleEngine {
    rust: Query,
    python: Query,
    typescript: Query,
    javascript: Query,
}

impl RuleEngine {
    /// Creates a new rule engine.
    ///
    /// # Panics
    ///
    /// Panics if the internal Tree-sitter queries are invalid.
    #[must_use]
    pub fn new() -> Self {
        Self {
            rust: Query::new(
                tree_sitter_rust::language(),
                "(function_item name: (identifier) @name)",
            )
            .unwrap(),
            python: Query::new(
                tree_sitter_python::language(),
                "(function_definition name: (identifier) @name)",
            )
            .unwrap(),
            typescript: Query::new(
                tree_sitter_typescript::language_typescript(),
                r"
                (function_declaration name: (identifier) @name)
                (method_definition name: (property_identifier) @name)
                (variable_declarator name: (identifier) @name value: [(arrow_function) (function_expression)])
            ",
            )
            .unwrap(),
            javascript: Query::new(
                tree_sitter_javascript::language(),
                r"
                (function_declaration name: (identifier) @name)
                (method_definition name: (property_identifier) @name)
                (variable_declarator name: (identifier) @name value: [(arrow_function) (function_expression)])
            ",
            )
            .unwrap(),
        }
    }

    /// Checks a file for rule violations.
    ///
    /// # Errors
    ///
    /// Returns error if the file cannot be read.
    pub fn check_file(&self, path: &Path) -> Result<bool> {
        let Ok(content) = fs::read_to_string(path) else {
            return Ok(true);
        };

        if content.contains("// warden:ignore") || content.contains("# warden:ignore") {
            return Ok(true);
        }

        let mut passed = true;
        let filename = path.to_string_lossy();

        // 1. TOKEN COUNT
        let token_count = Tokenizer::count(&content);
        if token_count > TOKEN_LIMIT {
            println!(
                "{} {}: {} tokens (Limit: {}). Split this file.",
                "[BLOAT]".red().bold(),
                filename,
                token_count,
                TOKEN_LIMIT
            );
            passed = false;
        }

        // 2. AST ANALYSIS
        if let Some(ext) = path.extension().and_then(|s| s.to_str()) {
            match ext {
                "rs" => Self::analyze_tree(
                    tree_sitter_rust::language(),
                    &self.rust,
                    &content,
                    &filename,
                    "_",
                    &mut passed,
                ),
                "py" => Self::analyze_tree(
                    tree_sitter_python::language(),
                    &self.python,
                    &content,
                    &filename,
                    "_",
                    &mut passed,
                ),
                "ts" | "tsx" => Self::analyze_tree(
                    tree_sitter_typescript::language_typescript(),
                    &self.typescript,
                    &content,
                    &filename,
                    "camel",
                    &mut passed,
                ),
                "js" | "jsx" => Self::analyze_tree(
                    tree_sitter_javascript::language(),
                    &self.javascript,
                    &content,
                    &filename,
                    "camel",
                    &mut passed,
                ),
                _ => {}
            }
        }

        Ok(passed)
    }

    fn analyze_tree(
        language: Language,
        query: &Query,
        content: &str,
        filename: &str,
        naming_style: &str,
        passed: &mut bool,
    ) {
        let mut parser = Parser::new();
        parser
            .set_language(language)
            .expect("Error loading grammar");

        let tree = parser.parse(content, None).expect("Error parsing file");
        let root = tree.root_node();

        // A. NAMING
        let mut cursor = QueryCursor::new();
        for m in cursor.matches(query, root, content.as_bytes()) {
            for capture in m.captures {
                let name_bytes = &content.as_bytes()[capture.node.byte_range()];
                let name = String::from_utf8_lossy(name_bytes);

                if naming_style == "camel" {
                    let caps = name.chars().filter(|c| c.is_uppercase()).count();
                    // Collapsed if block
                    if caps + 1 > WORD_LIMIT && !name.chars().next().unwrap_or('a').is_uppercase() {
                        Self::report_naming(filename, &name, passed);
                    }
                } else if name.split('_').count() > WORD_LIMIT {
                    Self::report_naming(filename, &name, passed);
                }
            }
        }

        // B. SAFETY (Recursive walk)
        Self::check_safety_recursive(root, content, filename, passed);
    }

    fn report_naming(filename: &str, name: &str, passed: &mut bool) {
        println!(
            "{} {}: Function '{}' is too complex (Limit: 3 words).",
            "[NAMING]".red().bold(),
            filename,
            name
        );
        *passed = false;
    }

    fn check_safety_recursive(node: Node, content: &str, filename: &str, passed: &mut bool) {
        let kind = node.kind();

        let is_func_body =
            kind.contains("block") || kind == "function_definition" || kind == "arrow_function";

        if is_func_body {
            let code_bytes = &content.as_bytes()[node.byte_range()];
            let code_str = String::from_utf8_lossy(code_bytes).to_lowercase();

            // Skip short functions
            if code_str.lines().count() < 5 {
                return;
            }

            let has_safety = code_str.contains("result")
                || code_str.contains("option")
                || code_str.contains("try")
                || code_str.contains("catch")
                || code_str.contains("except")
                || code_str.contains("match")
                || code_str.contains("unwrap_or")
                || code_str.contains("ok(");

            if !has_safety {
                println!(
                    "{} {}: Logic block missing explicit safety (try/catch/Result).",
                    "[UNSAFE]".yellow().bold(),
                    filename
                );
                *passed = false;
            }
        }

        // Recurse
        let mut cursor = node.walk();
        for child in node.children(&mut cursor) {
            Self::check_safety_recursive(child, content, filename, passed);
        }
    }
}

impl Default for RuleEngine {
    fn default() -> Self {
        Self::new()
    }
}


