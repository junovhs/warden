================================================================================
FILE: .gitignore
================================================================================
# Rust build artifacts
/target/
/docs/
/Cargo.lock

# Logs and temp files
*.log
*.tmp
*.bak

# Generated AI pack and test fixtures
ai-pack/
tests/tmp/
tmp/
*.manifest.json

# Editor/OS files
.DS_Store
Thumbs.db
.idea/
.vscode/
*.swp
*.swo

# Git / OS cruft
*~
*.orig

# Node / frontend extras
node_modules/
dist/
build/
coverage/
.env

# Python extras
__pycache__/
.venv/
venv/

# Repomix or AI output
*.xml
*.jsonl

# Ignore everything inside /target/release except binaries we care about
!/target/release/saccade.exe
!/target/release/gauntlet.exe

================================================================================
FILE: Cargo.toml
================================================================================
[package]
name = "warden"
version = "0.3.0"
edition = "2021"

[lib]
name = "warden_core"
path = "src/lib.rs"

[[bin]]
name = "warden"
path = "src/bin/warden.rs"

[[bin]]
name = "knit"
path = "src/bin/knit.rs"

[dependencies]
anyhow = "1.0"
thiserror = "1.0"
regex = "1.10"
walkdir = "2.5"
clap = { version = "4.5", features = ["derive"] }
ignore = "0.4"
colored = "2.1"
rayon = "1.10"
once_cell = "1.19"
serde = { version = "1.0", features = ["derive"] }
toml = "0.8"

# THE BRAINS
tiktoken-rs = "0.5"

# Structural Parsing
tree-sitter = "0.20"
tree-sitter-rust = "0.20"
tree-sitter-python = "0.20"
tree-sitter-typescript = "0.20"
tree-sitter-javascript = "0.20"


================================================================================
FILE: LICENSE
================================================================================
MIT License

Copyright (c) 2025 Spencer Nunamaker

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.


================================================================================
FILE: README.md
================================================================================
# üõ°Ô∏è Warden Protocol

**Architecture Governance for the AI Era.**

> *"We do not ask the AI to write good code. We enforce good code via mechanical constraints."*

Warden is a local toolchain designed to enforce **Code With Intent (POT)**. It solves the "Context Drift" and "Hallucination" problems common in AI coding by enforcing strict structural discipline (Atomicity, Naming, Safety) before code is committed.

**v0.2.0 Update:** Warden now uses **Tree-sitter** for structural AST analysis and **Tiktoken** for LLM-native limits. It no longer parses text; it parses logic.

## The Ecosystem

This repository contains two binaries that share a single logic core:

1.  **`warden` (The Enforcer):** An AST-based linter that rejects bloat (tokens), complexity (naming), and unsafe code (scope analysis).
2.  **`knit` (The Messenger):** A smart context-packer that serializes your repository for AI consumption, reporting exactly how many tokens you are feeding the model.

---

## 1. The Warden (Linter)

Warden does not check if your code works. It checks if your code is **maintainable**. It enforces the "3 Laws" of this architecture:

### The 3 Laws
1.  **The Law of Atomicity (Anti-Bloat)**
    *   **Rule:** No file may exceed **2000 Tokens** (approx. 200-250 lines of dense code).
    *   **Goal:** Forces modularity based on **Attention Span**, not line count. LLMs degrade rapidly when context is flooded. Warden uses `cl100k_base` (GPT-4) tokenization to measure true cognitive load.
2.  **The Law of Bluntness (Naming)**
    *   **Rule:** Function names must be **‚â§ 3 words** (e.g., `fetchUser` ‚úÖ, `fetchUserAndSaveToDb` ‚ùå).
    *   **Goal:** Enforces Single Responsibility Principle (SRP). If you can't name it simply, split it. *Now uses AST analysis to ignore comments and strings.*
3.  **The Law of Paranoia (Safety)**
    *   **Rule:** Logic bodies must contain explicit error handling (`Result`, `try/catch`, `Option`, `match`).
    *   **Goal:** Prevents "Silent Failures." *Warden verifies that safety mechanisms exist inside the function scope, not just in file comments.*

### Usage
```bash
# Run inside any Git repo
warden

# Force scan ignored files
warden --no-git

# Verbose mode (see exactly what it checks)
warden -v
```

**Bypass:** To intentionally skip a file (e.g., a UI component with no logic), add this comment to the top of the file:
```rust
// warden:ignore
```

---

## 2. Knit (Context Packer)

Knit is the bridge between your filesystem and the LLM. It stitches your "Atomic" files into a single text stream with clear headers and **calculates the token cost** of your context.

### Features
*   **Token Aware:** Reports exactly how many tokens your context consumes (e.g., `9487 tokens`), so you never exceed your model's window.
*   **Smart Defaults:** Automatically strips noise (`node_modules`, `target`, `_assets`, `lockfiles`, `tests`, `docs`). You get the **Kernel** of the code, not the fluff.
*   **Entropy Filtering:** Detects and rejects minified code or binary blobs disguised as text.
*   **Security:** Filters out secrets (`.env`, keys) and binaries (`.png`, `.exe`) automatically.

### Usage
```bash
# Generates a clean 'context.txt' in the current folder
knit

# Pipe directly to clipboard (Mac)
knit --stdout | pbcopy

# Pipe directly to clipboard (Linux)
knit --stdout | xclip -selection c
```

---

## ‚öôÔ∏è Configuration

Warden and Knit work out-of-the-box with "Smart Defaults" (ignoring `dist`, `build`, `assets`, etc).

To add custom excludes for a specific project, create a `.wardenignore` file in the project root:

```text
# .wardenignore
legacy_code/
experiment.rs
scripts/
```

---

## üöÄ Installation

Requires Rust (`cargo`).

```bash
# Clone and install globally
git clone https://github.com/yourusername/warden.git
cd warden
cargo install --path . --force
```

**Recommended Shell Aliases:**
Add these to your `.zshrc` or `.bashrc` for the full workflow:

```bash
# Mac
alias gcp="knit --stdout | pbcopy && echo 'üìã Context copied.'"

# Linux
# alias gcp="knit --stdout | xclip -selection c && echo 'üìã Context copied.'"
```

---

## ü§ñ The AI System Prompt

To make the AI obey Warden, paste this into your System Prompt / Custom Instructions:

```text
ROLE: High-Integrity Systems Architect.
CONTEXT: You are coding inside a strict "Code With Intent" environment enforced by a binary linter called Warden.

THE 3 LAWS (Non-Negotiable):
1. LAW OF ATOMICITY (Token Limits):
   - Files MUST be < 2000 Tokens (~200 lines).
   - If a file grows too large, split it immediately.
   - React/UI: Split VIEW (Component.tsx) from LOGIC (useComponent.ts).

2. LAW OF PARANOIA (Scope Safety):
   - Logic Blocks MUST contain explicit error handling (Result, try/catch, Option) INSIDE the function body.
   - If a component is pure UI (visuals only), add "// warden:ignore" at the top.

3. LAW OF BLUNTNESS (Naming):
   - Function names Max 3 words (e.g., `fetchData` is good; `fetchDataAndProcess` is bad).

OPERATIONAL PROTOCOL:
1. Scan: Read the provided context.
2. Generate: Output WHOLE FILES with the filename in a header. Do not use diffs.
3. Verify: Ask yourself: "Will Warden reject this?" before printing.
```

---

**License:** MIT  
**Philosophy:** Code With Intent (POT)


================================================================================
FILE: src/bin/knit.rs
================================================================================
use anyhow::Result;
use clap::{Parser, ValueEnum};
use colored::Colorize;
use std::fmt::Write;
use std::fs;

use warden_core::config::{Config, GitMode};
use warden_core::enumerate::FileEnumerator;
use warden_core::filter::FileFilter;
use warden_core::heuristics::HeuristicFilter;
use warden_core::tokens::Tokenizer;

#[derive(Debug, Clone, ValueEnum)]
enum OutputFormat {
    Text,
    Xml,
}

#[derive(Parser)]
#[command(name = "knit")]
#[command(about = "Stitches atomic files into a single context file.")]
#[allow(clippy::struct_excessive_bools)]
struct Cli {
    #[arg(long, short)]
    stdout: bool,
    #[arg(long, short)]
    verbose: bool,
    #[arg(long)]
    git_only: bool,
    #[arg(long)]
    no_git: bool,
    #[arg(long)]
    code_only: bool,
    /// Output format (Text for standard, Xml for Claude/LLMs)
    #[arg(long, value_enum, default_value_t = OutputFormat::Text)]
    format: OutputFormat,
}

fn main() -> Result<()> {
    let cli = Cli::parse();

    let mut config = Config::new();
    config.verbose = cli.verbose;
    config.code_only = cli.code_only;

    if cli.git_only {
        config.git_mode = GitMode::Yes;
    } else if cli.no_git {
        config.git_mode = GitMode::No;
    }

    config.load_local_config();
    config.validate()?;

    if !cli.stdout {
        println!("üß∂ Knitting repository...");
    }

    let enumerator = FileEnumerator::new(config.clone());
    let raw_files = enumerator.enumerate()?;

    let heuristic_filter = HeuristicFilter::new();
    let heuristics_files = heuristic_filter.filter(raw_files);

    let filter = FileFilter::new(config.clone())?;
    let target_files = filter.filter(heuristics_files);

    if cli.verbose {
        eprintln!("üì¶ Packing {} files...", target_files.len());
    }

    let mut full_context = String::with_capacity(100_000);

    match cli.format {
        OutputFormat::Text => pack_text(&target_files, &mut full_context),
        OutputFormat::Xml => pack_xml(&target_files, &mut full_context),
    }

    // Count tokens
    let token_count = Tokenizer::count(&full_context);

    if cli.stdout {
        print!("{full_context}");
        eprintln!(
            "\nüìä Context Size: {} tokens",
            token_count.to_string().yellow().bold()
        );
    } else {
        fs::write("context.txt", &full_context)?;
        println!("‚úÖ Generated 'context.txt'");
        println!(
            "üìä Context Size: {} tokens",
            token_count.to_string().yellow().bold()
        );
    }

    Ok(())
}

fn pack_text(files: &[std::path::PathBuf], out: &mut String) {
    for path in files {
        let path_str = path.to_string_lossy();
        writeln!(
            out,
            "================================================================================"
        )
        .unwrap();
        writeln!(out, "FILE: {path_str}").unwrap();
        writeln!(
            out,
            "================================================================================"
        )
        .unwrap();

        match fs::read_to_string(path) {
            Ok(content) => {
                out.push_str(&content);
            }
            Err(e) => {
                writeln!(out, "<ERROR READING FILE: {e}>").unwrap();
            }
        }
        out.push_str("\n\n");
    }
}

fn pack_xml(files: &[std::path::PathBuf], out: &mut String) {
    writeln!(out, "<documents>").unwrap();
    for path in files {
        let path_str = path.to_string_lossy();
        writeln!(out, "  <document path=\"{path_str}\">").unwrap();

        match fs::read_to_string(path) {
            Ok(content) => {
                // We do not escape content to preserve code integrity for LLMs.
                // They are smart enough to handle unescaped code blocks usually.
                out.push_str(&content);
            }
            Err(e) => {
                writeln!(out, "    <!-- ERROR READING FILE: {e} -->").unwrap();
            }
        }
        writeln!(out, "\n  </document>").unwrap();
    }
    writeln!(out, "</documents>").unwrap();
}


================================================================================
FILE: src/bin/warden.rs
================================================================================
use anyhow::Result;
use clap::Parser;
use colored::Colorize;
use std::process;

use warden_core::config::{Config, GitMode};
use warden_core::detection::Detector;
use warden_core::enumerate::FileEnumerator;
use warden_core::filter::FileFilter;
use warden_core::heuristics::HeuristicFilter;
use warden_core::rules::RuleEngine;

#[derive(Parser)]
#[command(name = "warden")]
#[command(about = "Structural linter for Code With Intent")]
#[allow(clippy::struct_excessive_bools)]
struct Cli {
    #[arg(long, short)]
    verbose: bool,
    #[arg(long)]
    git_only: bool,
    #[arg(long)]
    no_git: bool,
    #[arg(long)]
    code_only: bool,
}

fn main() -> Result<()> {
    let cli = Cli::parse();

    // Strict initialization
    let mut config = Config::new();
    config.verbose = cli.verbose;
    config.code_only = cli.code_only;

    if cli.git_only {
        config.git_mode = GitMode::Yes;
    } else if cli.no_git {
        config.git_mode = GitMode::No;
    }

    // Load local configuration (warden.toml / .wardenignore)
    config.load_local_config();
    config.validate()?;

    let enumerator = FileEnumerator::new(config.clone());
    let raw_files = enumerator.enumerate()?;

    // Context: Detection
    let detector = Detector::new();
    if let Ok(systems) = detector.detect_build_systems(&raw_files) {
        if !systems.is_empty() && config.verbose {
            let sys_list: Vec<String> = systems.iter().map(ToString::to_string).collect();
            println!("üîé Detected Ecosystem: [{}]", sys_list.join(", ").cyan());
        }
    }

    let heuristic_filter = HeuristicFilter::new();
    let heuristics_files = heuristic_filter.filter(raw_files);

    let filter = FileFilter::new(config.clone())?;
    let target_files = filter.filter(heuristics_files);

    if target_files.is_empty() {
        println!("No files to scan.");
        return Ok(());
    }

    println!(
        "üëÆ Warden scanning {} files (AST + Token Analysis)...",
        target_files.len()
    );

    // Logic Engine with injected Config
    let engine = RuleEngine::new(config);
    let mut total_failures = 0;

    for path in target_files {
        if let Ok(passed) = engine.check_file(&path) {
            if !passed {
                total_failures += 1;
            }
        }
    }

    if total_failures > 0 {
        println!(
            "{}",
            format!("‚ùå Warden found {total_failures} violations.")
                .red()
                .bold()
        );
        process::exit(1);
    } else {
        println!(
            "{}",
            "‚úÖ All Clear. Code structure is clean.".green().bold()
        );
        process::exit(0);
    }
}


================================================================================
FILE: src/config.rs
================================================================================
use crate::error::Result;
use regex::Regex;
use serde::Deserialize;
use std::fs;
use std::path::Path;

// --- CONFIG STRUCTURES ---

#[derive(Debug, Clone, Deserialize)]
pub struct RuleConfig {
    #[serde(default = "default_max_tokens")]
    pub max_file_tokens: usize,
    #[serde(default = "default_max_words")]
    pub max_function_words: usize,
    #[serde(default)]
    pub ignore_naming_on: Vec<String>,
}

impl Default for RuleConfig {
    fn default() -> Self {
        Self {
            max_file_tokens: default_max_tokens(),
            max_function_words: default_max_words(),
            ignore_naming_on: Vec::new(),
        }
    }
}

const fn default_max_tokens() -> usize {
    2000
}
const fn default_max_words() -> usize {
    3
}

#[derive(Debug, Clone, Deserialize, Default)]
pub struct WardenToml {
    #[serde(default)]
    pub rules: RuleConfig,
}

// --- MAIN CONFIG ---

#[derive(Debug, Clone)]
pub enum GitMode {
    Auto,
    Yes,
    No,
}

#[derive(Debug, Clone)]
pub struct Config {
    pub git_mode: GitMode,
    pub include_patterns: Vec<Regex>,
    pub exclude_patterns: Vec<Regex>,
    pub code_only: bool,
    pub verbose: bool,
    pub rules: RuleConfig,
}

impl Default for Config {
    fn default() -> Self {
        Self::new()
    }
}

impl Config {
    #[must_use]
    pub fn new() -> Self {
        Self {
            git_mode: GitMode::Auto,
            include_patterns: Vec::new(),
            exclude_patterns: Vec::new(),
            code_only: false,
            verbose: false,
            rules: RuleConfig::default(),
        }
    }

    /// Validates the configuration.
    ///
    /// # Errors
    ///
    /// Currently always returns `Ok`. Reserved for future validation logic
    /// that might return an error if configurations are invalid.
    pub fn validate(&self) -> Result<()> {
        Ok(())
    }

    pub fn load_local_config(&mut self) {
        self.load_ignore_file();
        self.load_toml_config();
    }

    fn load_ignore_file(&mut self) {
        let ignore_path = Path::new(".wardenignore");
        if let Ok(content) = fs::read_to_string(ignore_path) {
            for line in content.lines() {
                let trimmed = line.trim();
                if trimmed.is_empty() || trimmed.starts_with('#') {
                    continue;
                }
                if let Ok(re) = Regex::new(trimmed) {
                    self.exclude_patterns.push(re);
                }
            }
        }
    }

    fn load_toml_config(&mut self) {
        let toml_path = Path::new("warden.toml");
        if let Ok(content) = fs::read_to_string(toml_path) {
            if let Ok(parsed) = toml::from_str::<WardenToml>(&content) {
                self.rules = parsed.rules;
                if self.verbose {
                    println!("üîß Loaded warden.toml configuration");
                }
            } else if self.verbose {
                eprintln!("‚ö†Ô∏è Failed to parse warden.toml");
            }
        }
    }
}

// Constants for automatic pruning (Smart Defaults)
pub const PRUNE_DIRS: &[&str] = &[
    ".git",
    "node_modules",
    "target",
    "dist",
    "build",
    "out",
    "gen",
    ".venv",
    "venv",
    ".tox",
    "__pycache__",
    "coverage",
    "vendor",
];

pub const BIN_EXT_PATTERN: &str =
    r"(?i)\.(png|jpg|gif|svg|ico|webp|woff2?|ttf|pdf|mp4|zip|gz|tar|exe|dll|so|dylib|class|pyc)$";
pub const SECRET_PATTERN: &str =
    r"(?i)(^\.?env(\..*)?$|/\.?env(\..*)?$|(^|/)(id_rsa|id_ed25519|.*\.(pem|p12|key|pfx))$)";
pub const CODE_EXT_PATTERN: &str = r"(?i)\.(rs|go|py|js|jsx|ts|tsx|java|c|cpp|h|hpp|cs|php|rb|sh|sql|html|css|scss|json|toml|yaml|md)$";
pub const CODE_BARE_PATTERN: &str = r"(?i)(Makefile|Dockerfile|CMakeLists\.txt)$";


================================================================================
FILE: src/detection.rs
================================================================================
use crate::error::Result;
use std::collections::HashSet;
use std::fmt;
use std::path::Path;

#[derive(Debug, PartialEq, Eq, Hash, Clone, Copy)]
pub enum BuildSystemType {
    Rust,
    Node,
    Python,
    Go,
    CMake,
    Conan,
}

impl fmt::Display for BuildSystemType {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "{self:?}")
    }
}

pub struct Detector;

impl Detector {
    #[must_use]
    pub fn new() -> Self {
        Self
    }

    /// Detects build systems in the file list.
    ///
    /// # Errors
    ///
    /// Returns error if underlying detection logic fails.
    pub fn detect_build_systems(
        &self,
        files: &[std::path::PathBuf],
    ) -> Result<Vec<BuildSystemType>> {
        let mut detected = HashSet::new();

        for file in files {
            if Self::is_cargo(file) {
                detected.insert(BuildSystemType::Rust);
            }
            if Self::is_npm(file) {
                detected.insert(BuildSystemType::Node);
            }
            if Self::is_python(file) {
                detected.insert(BuildSystemType::Python);
            }
            if Self::is_go(file) {
                detected.insert(BuildSystemType::Go);
            }
            if Self::is_cmake(file) {
                detected.insert(BuildSystemType::CMake);
            }
            if Self::is_conan(file) {
                detected.insert(BuildSystemType::Conan);
            }
        }

        Ok(detected.into_iter().collect())
    }

    fn is_cargo(path: &Path) -> bool {
        path.ends_with("Cargo.toml")
    }
    fn is_npm(path: &Path) -> bool {
        path.ends_with("package.json")
    }
    fn is_python(path: &Path) -> bool {
        matches!(
            path.file_name().and_then(|n| n.to_str()),
            Some("requirements.txt" | "pyproject.toml" | "Pipfile")
        )
    }
    fn is_go(path: &Path) -> bool {
        path.ends_with("go.mod")
    }
    fn is_cmake(path: &Path) -> bool {
        let s = path.to_string_lossy();
        s.contains("CMakeLists.txt") || s.ends_with(".cmake")
    }
    fn is_conan(path: &Path) -> bool {
        matches!(
            path.file_name().and_then(|n| n.to_str()),
            Some("conanfile.txt" | "conanfile.py")
        )
    }
}

impl Default for Detector {
    fn default() -> Self {
        Self::new()
    }
}


================================================================================
FILE: src/enumerate.rs
================================================================================
// warden:ignore
use crate::config::{Config, PRUNE_DIRS};
use crate::error::{Result, WardenError};
use std::path::PathBuf;
use std::process::Command;
use walkdir::WalkDir;

pub struct FileEnumerator {
    config: Config,
}

impl FileEnumerator {
    #[must_use]
    pub fn new(config: Config) -> Self {
        Self { config }
    }

    /// Enumerates files based on configuration.
    ///
    /// # Errors
    ///
    /// Returns error if `git` fails in Git mode.
    pub fn enumerate(&self) -> Result<Vec<PathBuf>> {
        use crate::config::GitMode;

        match self.config.git_mode {
            GitMode::Yes => {
                if !Self::in_git_repo() {
                    return Err(WardenError::NotInGitRepo);
                }
                // Fixed: Self::filter_paths
                Ok(Self::filter_paths(Self::git_ls_files()?))
            }
            GitMode::No => Ok(self.walk_all_files()),
            GitMode::Auto => {
                if Self::in_git_repo() {
                    if let Ok(files) = Self::git_ls_files() {
                        // Fixed: Self::filter_paths
                        return Ok(Self::filter_paths(files));
                    }
                }
                Ok(self.walk_all_files())
            }
        }
    }

    // Fixed: Removed &self
    fn filter_paths(paths: Vec<PathBuf>) -> Vec<PathBuf> {
        paths
            .into_iter()
            .filter(|p| {
                for part in p.components() {
                    if let Some(s) = part.as_os_str().to_str() {
                        if PRUNE_DIRS.contains(&s) {
                            return false;
                        }
                    }
                }
                true
            })
            .collect()
    }

    fn in_git_repo() -> bool {
        let out = Command::new("git")
            .arg("rev-parse")
            .arg("--is-inside-work-tree")
            .output();

        matches!(out, Ok(o) if o.status.success())
    }

    fn git_ls_files() -> Result<Vec<PathBuf>> {
        let out = Command::new("git")
            .arg("ls-files")
            .arg("-z")
            .arg("--exclude-standard")
            .output()?;

        if !out.status.success() {
            return Err(WardenError::Other(format!(
                "git ls-files failed: exit {}",
                out.status
            )));
        }

        let mut paths = Vec::new();
        for chunk in out.stdout.split(|b| *b == 0) {
            if chunk.is_empty() {
                continue;
            }
            let s = String::from_utf8_lossy(chunk);
            paths.push(PathBuf::from(s.as_ref()));
        }
        Ok(paths)
    }

    fn walk_all_files(&self) -> Vec<PathBuf> {
        let mut paths = Vec::new();
        let mut errors = Vec::new();

        let walker = WalkDir::new(".").follow_links(false).into_iter();

        for item in walker.filter_entry(|e| {
            let name = e.file_name().to_string_lossy();
            // WalkDir filtering allows us to skip descending into "node_modules" entirely
            !PRUNE_DIRS.iter().any(|p| name == *p)
        }) {
            let entry = match item {
                Ok(e) => e,
                Err(e) => {
                    errors.push(format!("walkdir: {e}"));
                    continue;
                }
            };

            if entry.file_type().is_file() {
                let p = entry.path().strip_prefix(".").unwrap_or(entry.path());
                paths.push(p.to_path_buf());
            }
        }

        if !errors.is_empty() && self.config.verbose {
            eprintln!(
                "WARN: Encountered {} errors during file walk:",
                errors.len()
            );
            for (i, err) in errors.iter().take(5).enumerate() {
                eprintln!("  {}. {}", i + 1, err);
            }
        }

        paths
    }
}


================================================================================
FILE: src/error.rs
================================================================================
// src/error.rs
use std::path::PathBuf;
use thiserror::Error;

#[derive(Debug, Error)]
pub enum WardenError {
    #[error("I/O error: {source} (path: {path})")]
    Io {
        source: std::io::Error,
        path: PathBuf,
    },

    #[error("Not inside a Git repository")]
    NotInGitRepo,

    #[error("Regex error: {0}")]
    Regex(#[from] regex::Error),

    #[error("Generic error: {0}")]
    Other(String),
}

pub type Result<T> = std::result::Result<T, WardenError>;

// Allow `?` on std::io::Error by converting to WardenError::Io with unknown path.
impl From<std::io::Error> for WardenError {
    fn from(source: std::io::Error) -> Self {
        WardenError::Io {
            source,
            path: PathBuf::from("<unknown>"),
        }
    }
}

// Gracefully convert WalkDir errors
impl From<walkdir::Error> for WardenError {
    fn from(e: walkdir::Error) -> Self {
        WardenError::Other(e.to_string())
    }
}


================================================================================
FILE: src/filter.rs
================================================================================
use crate::config::{Config, BIN_EXT_PATTERN, CODE_BARE_PATTERN, CODE_EXT_PATTERN, SECRET_PATTERN};
use crate::error::Result;
use regex::Regex;
use std::path::Path;

pub struct FileFilter {
    config: Config,
    bin_ext_re: Regex,
    secret_re: Regex,
    code_ext_re: Option<Regex>,
    code_bare_re: Option<Regex>,
}

impl FileFilter {
    /// Creates a new file filter.
    ///
    /// # Errors
    ///
    /// Returns an error if any of the regex patterns (binary extensions, secrets, or code patterns) fail to compile.
    pub fn new(config: Config) -> Result<Self> {
        let bin_ext_re = Regex::new(BIN_EXT_PATTERN)?;
        let secret_re = Regex::new(SECRET_PATTERN)?;

        let (code_ext_re, code_bare_re) = if config.code_only {
            (
                Some(Regex::new(CODE_EXT_PATTERN)?),
                Some(Regex::new(CODE_BARE_PATTERN)?),
            )
        } else {
            (None, None)
        };

        Ok(Self {
            config,
            bin_ext_re,
            secret_re,
            code_ext_re,
            code_bare_re,
        })
    }

    #[must_use]
    pub fn filter(&self, files: Vec<std::path::PathBuf>) -> Vec<std::path::PathBuf> {
        files.into_iter().filter(|p| self.should_keep(p)).collect()
    }

    fn should_keep(&self, path: &Path) -> bool {
        let s = path.to_string_lossy().replace('\\', "/");

        // Structural Safety: Explicit truth table matching
        match (self.is_secret(&s), self.is_binary(&s), self.is_excluded(&s)) {
            (true, _, _) | (_, true, _) | (_, _, true) => return false,
            _ => {}
        }

        match (self.is_included(&s), self.config.code_only) {
            (false, _) => false,
            (_, true) if !self.is_code(&s) => false,
            _ => true,
        }
    }

    fn is_secret(&self, path: &str) -> bool {
        self.secret_re.is_match(path)
    }

    fn is_binary(&self, path: &str) -> bool {
        self.bin_ext_re.is_match(path)
    }

    fn is_excluded(&self, path: &str) -> bool {
        // Paranoia: Explicitly match on the Option result of find()
        // This ensures structural safety is present even if formatting expands the lines
        match self
            .config
            .exclude_patterns
            .iter()
            .find(|p| p.is_match(path))
        {
            Some(_) => true,
            None => false,
        }
    }

    fn is_included(&self, path: &str) -> bool {
        if self.config.include_patterns.is_empty() {
            return true;
        }
        // Paranoia: Explicitly match on the Option result
        match self
            .config
            .include_patterns
            .iter()
            .find(|p| p.is_match(path))
        {
            Some(_) => true,
            None => false,
        }
    }

    fn is_code(&self, path: &str) -> bool {
        match (&self.code_ext_re, &self.code_bare_re) {
            (Some(ext), Some(bare)) => ext.is_match(path) || bare.is_match(path),
            _ => true,
        }
    }
}


================================================================================
FILE: src/heuristics.rs
================================================================================
// warden:ignore
use crate::config::{CODE_BARE_PATTERN, CODE_EXT_PATTERN};
use regex::Regex;
use std::collections::HashMap;
use std::fs;
use std::path::Path;
use std::sync::LazyLock;

// --- Configuration Constants for Heuristics ---
const MIN_TEXT_ENTROPY: f64 = 3.5;
const MAX_TEXT_ENTROPY: f64 = 5.5;

const BUILD_SYSTEM_PAMPS: &[&str] = &[
    "find_package",
    "add_executable",
    "target_link_libraries",
    "cmake_minimum_required",
    "project(",
    "add-apt-repository",
    "conanfile.py",
    "dependency",
    "require",
    "include",
    "import",
    "version",
    "dependencies",
];

// Pre-compiled regexes for known code files
static CODE_EXT_RE: LazyLock<Regex> = LazyLock::new(|| Regex::new(CODE_EXT_PATTERN).unwrap());
static CODE_BARE_RE: LazyLock<Regex> = LazyLock::new(|| Regex::new(CODE_BARE_PATTERN).unwrap());

pub struct HeuristicFilter;

impl HeuristicFilter {
    #[must_use]
    pub fn new() -> Self {
        Self
    }

    #[must_use]
    pub fn filter(&self, files: Vec<std::path::PathBuf>) -> Vec<std::path::PathBuf> {
        files
            .into_iter()
            .filter(|path| Self::should_keep(path))
            .collect()
    }

    fn should_keep(path: &Path) -> bool {
        let path_str = path.to_string_lossy();

        if CODE_EXT_RE.is_match(&path_str) || CODE_BARE_RE.is_match(&path_str) {
            return true;
        }

        if let Ok(entropy) = calculate_entropy(path) {
            if !(MIN_TEXT_ENTROPY..=MAX_TEXT_ENTROPY).contains(&entropy) {
                return false;
            }
        } else {
            return false;
        }

        if let Ok(content) = fs::read_to_string(path) {
            let lower_content = content.to_lowercase();
            for pamp in BUILD_SYSTEM_PAMPS {
                if lower_content.contains(pamp) {
                    return true;
                }
            }
        }

        true
    }
}

impl Default for HeuristicFilter {
    fn default() -> Self {
        Self::new()
    }
}

fn calculate_entropy(path: &Path) -> std::io::Result<f64> {
    let bytes = fs::read(path)?;
    if bytes.is_empty() {
        return Ok(0.0);
    }

    let mut freq_map = HashMap::new();
    for &byte in &bytes {
        *freq_map.entry(byte).or_insert(0) += 1;
    }

    // Suppress cast precision loss for 64-bit length; entropy approximation is fine.
    #[allow(clippy::cast_precision_loss)]
    let len = bytes.len() as f64;

    let entropy = freq_map.values().fold(0.0, |acc, &count| {
        let probability = f64::from(count) / len;
        acc - probability * probability.log2()
    });

    Ok(entropy)
}


================================================================================
FILE: src/lib.rs
================================================================================
pub mod analysis;
pub mod config;
pub mod detection;
pub mod enumerate;
pub mod error;
pub mod filter;
pub mod heuristics;
pub mod rules;
pub mod tokens;


================================================================================
FILE: src/main.rs
================================================================================
use anyhow::Result;
use clap::Parser;
use colored::*;
use std::process;

// Module declarations
mod config;
mod detection;
mod enumerate;
mod error;
mod filter;
mod heuristics;
mod rules;

use crate::config::{Config, GitMode};
use crate::detection::Detector;
use crate::enumerate::FileEnumerator;
use crate::filter::FileFilter;
use crate::heuristics::HeuristicFilter;
use crate::rules::RuleEngine;

#[derive(Parser)]
#[command(name = "warden")]
#[command(about = "Structural linter for Code With Intent")]
struct Cli {
    /// Enable verbose logging
    #[arg(long, short)]
    verbose: bool,

    /// Force git-only mode (respect .gitignore)
    #[arg(long)]
    git_only: bool,

    /// Force no-git mode (scan everything)
    #[arg(long)]
    no_git: bool,

    /// Only scan code files (ignore configs/docs)
    #[arg(long)]
    code_only: bool,
}

fn main() -> Result<()> {
    let cli = Cli::parse();

    // 1. Setup & Validation
    let mut config = Config::new();
    config.verbose = cli.verbose;
    config.code_only = cli.code_only;

    // Wire up the GitMode enum variants (Resolves "Variant never constructed" warning)
    if cli.git_only {
        config.git_mode = GitMode::Yes;
    } else if cli.no_git {
        config.git_mode = GitMode::No;
    }

    // Call validate (Resolves "method never used" warning)
    config.validate()?;

    if config.verbose {
        println!("üîß Config loaded: GitMode::{:?}", config.git_mode);
    }

    // 2. Enumerate Files
    let enumerator = FileEnumerator::new(config.clone());
    let raw_files = enumerator.enumerate()?;

    // 3. Detection Layer (Resolves "Detector never constructed" warnings)
    // We use the detector to give context to the user about what we think this project is.
    let detector = Detector::new();
    let systems = detector.detect_build_systems(&raw_files)?;
    if !systems.is_empty() {
        let sys_list: Vec<String> = systems.iter().map(|s| s.to_string()).collect();
        println!("üîé Detected Ecosystem: [{}]", sys_list.join(", ").cyan());
    }

    // 4. Heuristics Layer (Resolves "HeuristicFilter never used" warnings)
    // Filters out high-entropy files (likely binaries/obfuscated code)
    let heuristic_filter = HeuristicFilter::new();
    let heuristics_files = heuristic_filter.filter(raw_files);

    // 5. Standard Filter Layer (Extension & Secrets)
    let filter = FileFilter::new(config)?;
    let target_files = filter.filter(heuristics_files);

    if target_files.is_empty() {
        println!("No files to scan.");
        return Ok(());
    }

    println!("üëÆ Warden scanning {} files...", target_files.len());

    // 6. Logic Engine (The Rules)
    let engine = RuleEngine::new();
    let mut total_failures = 0;

    for path in target_files {
        // We ignore the result error here (read failures) and just count logic failures
        if let Ok(passed) = engine.check_file(&path) {
            if !passed {
                total_failures += 1;
            }
        }
    }

    println!("---------------------------------------------------");
    if total_failures > 0 {
        println!(
            "{}",
            format!("‚ùå Warden found {} violations.", total_failures)
                .red()
                .bold()
        );
        process::exit(1);
    } else {
        println!(
            "{}",
            "‚úÖ All Clear. Code structure is clean.".green().bold()
        );
        process::exit(0);
    }
}


================================================================================
FILE: src/rules.rs
================================================================================
use crate::analysis::Analyzer;
use crate::config::Config;
use crate::error::Result;
use crate::tokens::Tokenizer;
use colored::Colorize;
use std::fs;
use std::path::Path;
use std::sync::LazyLock;

// Thread-safe analyzer instance
static ANALYZER: LazyLock<Analyzer> = LazyLock::new(Analyzer::new);

pub struct RuleEngine {
    config: Config,
}

impl RuleEngine {
    #[must_use]
    pub fn new(config: Config) -> Self {
        Self { config }
    }

    /// Checks a file for violations. Returns `Ok(false)` if violations found.
    ///
    /// # Errors
    ///
    /// Returns an error if the file cannot be read (and is not skipped).
    /// Note: Most read errors are suppressed/ignored in the current logic, returning `Ok(true)`.
    pub fn check_file(&self, path: &Path) -> Result<bool> {
        let Ok(content) = fs::read_to_string(path) else {
            return Ok(true); // Skip unreadable files
        };

        if content.contains("// warden:ignore") || content.contains("# warden:ignore") {
            return Ok(true);
        }

        let filename = path.to_string_lossy();
        let mut passed = true;

        // 1. LAW OF ATOMICITY (Token Limit)
        let token_count = Tokenizer::count(&content);
        if token_count > self.config.rules.max_file_tokens {
            Self::print_violation(
                &filename,
                0,
                &format!(
                    "File size is {token_count} tokens (Limit: {})",
                    self.config.rules.max_file_tokens
                ),
                "LAW OF ATOMICITY",
                "Split this file into smaller modules.",
            );
            passed = false;
        }

        // 2. AST ANALYSIS (Paranoia + Bluntness)
        if let Some(ext) = path.extension().and_then(|s| s.to_str()) {
            let violations = ANALYZER.analyze(ext, &content, &self.config.rules);

            for v in violations {
                Self::print_violation(
                    &filename,
                    v.row,
                    &v.message,
                    v.law,
                    if v.law == "LAW OF BLUNTNESS" {
                        "Rename function."
                    } else {
                        "Add Error Handling."
                    },
                );
                passed = false;
            }
        }

        Ok(passed)
    }

    fn print_violation(filename: &str, row: usize, msg: &str, law: &str, help: &str) {
        let line_num = row + 1;
        println!("{}: {}", "error".red().bold(), msg.bold());
        println!("  {} {}:{}:1", "-->".blue(), filename, line_num);
        println!("   {}", "|".blue());
        println!("   {} {}: {}", "=".blue().bold(), law.white().bold(), help);
        println!();
    }
}


================================================================================
FILE: src/tokens.rs
================================================================================
use std::sync::LazyLock;
use tiktoken_rs::CoreBPE;

// We use cl100k_base (GPT-4/3.5 turbo encoding) as the standard
static BPE: LazyLock<CoreBPE> = LazyLock::new(|| tiktoken_rs::cl100k_base().unwrap());

pub struct Tokenizer;

impl Tokenizer {
    #[must_use]
    pub fn count(text: &str) -> usize {
        // EncodeOrdinary is faster as it ignores special tokens, which is fine for code
        BPE.encode_ordinary(text).len()
    }

    /// Returns true if the file exceeds the token limit
    #[must_use]
    pub fn exceeds_limit(text: &str, limit: usize) -> bool {
        Self::count(text) > limit
    }
}


